#!/usr/bin/env python2

import sys, argparse, distutils, os, logging
from distutils.spawn import find_executable
from snpiphy import configure_outdir, SnpiPhy

# Import arguments
parser = argparse.ArgumentParser(description="snpiphy - An automated snp phylogeny pipeline.")
optional = parser._action_groups.pop()
required = parser.add_argument_group('required arguments')

required.add_argument("-q", "--fastq-dir", required=True, help="Path to a directory with your interleaved fastq sequencing reads or fasta assemblies.", action="store", dest="reads_dir")
required.add_argument("-o", "--output-directory", required=True, help="Path to the output directory. A directory will be created if one does not exist.", action="store", dest="outdir")
required.add_argument("-r", "--reference", required=True, help="Path to the reference sequence. Only fasta format is accepted currently.", action="store", dest="reference")
optional.add_argument("-c", "--cov-cutoff", help="Percent coverage of reference sequence (0-100%%) used to reject a sample. Samples lower than this threshold will be excluded from phylogenetic pipeline steps. Defaults to 85%%.", action="store", dest="cutoff", type=int, default=85)
optional.add_argument('-p', '--prefix', help='Prefix for output files', action='store', dest='prefix', default='')
optional.add_argument("-t", "--threads", help="Number of threads to use for multiprocessing.", action="store", dest="threads", type=int, default=1)
optional.add_argument("-f", "--force", help="Overwrite files in the output directories.", action='store_true', default=False)
optional.add_argument('--version', action='version', version='%(prog)s 0.1')
optional.add_argument('-v', '--verbose', help="Increase verbosity on command line output (n.b. verbose output is always saved to snpiphy.log in the output directory).", action='store_true', default=False)

parser._action_groups.append(optional)

args = parser.parse_args()

configure_outdir(os.path.abspath(args.outdir), args.force)

logger = logging.getLogger("snpiphy")
logger.setLevel(logging.DEBUG)
fh = logging.FileHandler(os.path.join(args.outdir, '{}.log'.format('.'.join((args.prefix, 'snpiphy')))))
fh.setLevel(logging.DEBUG)
ch = logging.StreamHandler()
if args.verbose == True:
	ch.setLevel(logging.DEBUG)
	formatter = logging.Formatter('%(asctime)s:%(name)s:%(levelname)s:%(message)s')
else:
	ch.setLevel(logging.INFO)
	formatter = logging.Formatter('%(asctime)s:%(levelname)s:%(message)s')
fh.setFormatter(formatter)
ch.setFormatter(formatter)
logger.addHandler(fh)
logger.addHandler(ch)

logger.info("Beginning snpiphy run...\n")

if args.force == True:
	logger.info("Force option given. Deleting previous snpiphy run...\n")

#Check for dependencies
logger.info("Checking dependencies...\n")
if not find_executable("bwa"):
	logger.error("bwa not found. Please install the bwa read aligner.")
	sys.exit(1)
if not find_executable("samtools"):
	logger.error("samtools not found. Please install samtools.")
	sys.exit(1)
if not find_executable("freebayes"):
	logger.error("freebayes not found. Please install the freebayes variant caller.")
	sys.exit(1)
if not find_executable("FastTree"):
	logger.error("FastTree not found. Please install the FastTree phylogenetics pipeline.")
	sys.exit(1)
if not find_executable("raxmlHPC-PTHREADS"):
	logger.error("raxml not found. Please install the raxml phylogenetics pipeline.")
	sys.exit(1)
if not find_executable("fastq-dump"):
	logger.error("sra-tools not found. Please install the sra-tools suite.")
	sys.exit(1)
if not find_executable("snippy"):
	logger.error("snippy not found. Please install snippy.")
	sys.exit(1)
if not find_executable("run_gubbins.py"):
	logger.error("gubbins not found. Please install gubbins.")
	sys.exit(1)

logger.info("All dependencies found.\n")

logger.info("Running snpiphy with the following options:")
logger.info("Reads directory = {}".format(args.reads_dir))
logger.info("output-directory = {}".format(args.outdir))
logger.info("threads = {}".format(args.threads))
logger.info("coverage cutoff = {}".format(args.cutoff))
logger.info("Force overwrite of previous output: {}".format(args.force))
logger.info("prefix = {}\n".format(args.prefix))

job = SnpiPhy(args.threads, args.cutoff, args.reads_dir, args.outdir, args.reference, args.prefix)
job.remove_results_without_reads()
logger.info("Processing {} samples:\n".format(len(job.sample_names)))
logger.debug("Samples to process:\n\n{}\n".format('\n'.join(job.sample_names)))
logger.debug("Samples that need reference alignment:\n\n{}\n".format('\n'.join(job.snippy_not_done)))
logger.info("STEP 1: Aligning sequences to reference genome...\n")
if len(job.snippy_not_done) != 0:
	for read_path in job.snippy_not_done:
		job.run_snippy(read_path)
logger.info("STEP 2: Generating raw core genome alignment...\n")
job.run_snippy_core()
logger.info("STEP 3: Filtering Ns from genome alignment...\n")
job.Ns2gaps()
logger.info("STEP 4: Predicting and filtering recombination events from genome alignment...\n")
job.filter_recombinant_positions()
logger.info("STEP 5: Generating recombination event figure...\n")
job.visualise_recombination_predictions()
logger.info("STEP 6: Building maximum likelihood phylogenetic tree...\n")
job.gen_bootstrap_tree()
job.gen_final_tree()
logger.info("STEP 7: Performing pairwise core SNP counts...\n")
job.count_core_snps()
logger.info("Job complete, thanks for using snpiphy.")
